{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e0163db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (3.10.7)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.15.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.76.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.42.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.9)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.32.5)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (6.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2025.10.5)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\hp\\desktop\\reality_ai\\unet_env\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "# In a notebook cell add ! if running here, or run in terminal\n",
    "!pip install numpy pandas scikit-learn matplotlib tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3131c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36348aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATE these paths to your files\n",
    "TRAIN_CSV = r\"C:\\path\\to\\zillow\\cleaned\\city_time_series_train.csv\"\n",
    "TEST_CSV  = r\"C:\\path\\to\\zillow\\cleaned\\city_time_series_test.csv\"\n",
    "\n",
    "TARGET = 'zhvi_allhomes'\n",
    "FEATURES = [\n",
    "    'zhvi_middletier', 'zhvi_singlefamilyresidence', 'zhvi_toptier',\n",
    "    'zhvipersqft_allhomes', 'zhvi_bottomtier', 'zhvi_4bedroom',\n",
    "    'zhvi_3bedroom', 'zhvi_5bedroomormore', 'zhvi_2bedroom', 'zhvi_condocoop',\n",
    "    'zri_allhomes', 'zri_allhomesplusmultifamily', 'zri_singlefamilyresidencerental',\n",
    "    'pricetorentratio_allhomes', 'zripersqft_allhomes', 'year',\n",
    "    'month', 'pctofhomesdecreasinginvalues_allhomes', 'pctofhomesincreasinginvalues_allhomes',\n",
    "    'inventoryraw_allhomes', 'inventoryseasonallyadjusted_allhomes'\n",
    "]\n",
    "\n",
    "TIMESTEPS = 12   # 12 months -> predict next month\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 30\n",
    "MODEL_DIR = r\"C:\\Users\\HP\\Desktop\\Reality_AI\\zillow\\lstm_model\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ee0a94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (2888110, 29) Test: (857820, 29)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(TRAIN_CSV, parse_dates=['date'])\n",
    "test  = pd.read_csv(TEST_CSV, parse_dates=['date'])\n",
    "\n",
    "print(\"Train:\", train.shape, \"Test:\", test.shape)\n",
    "\n",
    "# Sort by region and date ‚Äî essential for sequence creation\n",
    "train = train.sort_values(['regionname','date']).reset_index(drop=True)\n",
    "test  = test.sort_values(['regionname','date']).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb32c60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sample shape: (1465, 29)\n",
      "Test sample shape: (520, 29)\n"
     ]
    }
   ],
   "source": [
    "# ‚ö†Ô∏è Work with only a few regions first to avoid memory crash\n",
    "sample_regions = train['regionname'].unique()[:10]  # first 10 regions\n",
    "train_sample = train[train['regionname'].isin(sample_regions)]\n",
    "test_sample  = test[test['regionname'].isin(sample_regions)]\n",
    "\n",
    "print(\"Train sample shape:\", train_sample.shape)\n",
    "print(\"Test sample shape:\", test_sample.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da86aa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function converts time-series data into sequences\n",
    "def create_sequences(df, features, target, timesteps):\n",
    "    X_list, y_list = [], []\n",
    "    groups = df.groupby('regionname')\n",
    "    for region, g in groups:\n",
    "        g = g.sort_values('date')\n",
    "        vals = g[features].values\n",
    "        targets = g[target].values\n",
    "        n = len(g)\n",
    "        if n <= timesteps:\n",
    "            continue\n",
    "        for i in range(n - timesteps):\n",
    "            X_window = vals[i:i+timesteps]\n",
    "            y_val = targets[i+timesteps]\n",
    "            if np.isnan(X_window).any() or np.isnan(y_val):\n",
    "                continue\n",
    "            X_list.append(X_window)\n",
    "            y_list.append(y_val)\n",
    "    X = np.array(X_list, dtype=np.float32)\n",
    "    y = np.array(y_list, dtype=np.float32)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f39984c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sequences: (1345, 12, 21)\n",
      "Test sequences: (400, 12, 21)\n"
     ]
    }
   ],
   "source": [
    "TIMESTEPS = 12  # 12 months per sequence\n",
    "TARGET = 'zhvi_allhomes'\n",
    "\n",
    "X_train_seq, y_train_seq = create_sequences(train_sample, FEATURES, TARGET, TIMESTEPS)\n",
    "X_test_seq, y_test_seq = create_sequences(test_sample, FEATURES, TARGET, TIMESTEPS)\n",
    "\n",
    "print(\"Train sequences:\", X_train_seq.shape)\n",
    "print(\"Test sequences:\", X_test_seq.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a19ee61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled train shape: (1345, 12, 21)\n",
      "Scaled test shape: (400, 12, 21)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "n_features = X_train_seq.shape[2]\n",
    "\n",
    "# Fit scaler on training data\n",
    "X_train_flat = X_train_seq.reshape(-1, n_features)\n",
    "scaler.fit(X_train_flat)\n",
    "\n",
    "# Apply scaling to train and test\n",
    "def scale_windows(X, scaler):\n",
    "    s = X.reshape(-1, X.shape[2])\n",
    "    s = scaler.transform(s)\n",
    "    return s.reshape(X.shape)\n",
    "\n",
    "X_train_scaled = scale_windows(X_train_seq, scaler)\n",
    "X_test_scaled = scale_windows(X_test_seq, scaler)\n",
    "\n",
    "print(\"Scaled train shape:\", X_train_scaled.shape)\n",
    "print(\"Scaled test shape:\", X_test_scaled.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12bb114b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\HP\\Desktop\\Reality_AI\\unet_env\\Lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py:148: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\HP\\Desktop\\Reality_AI\\unet_env\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 12, 128)           76800     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 12, 128)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 128321 (501.25 KB)\n",
      "Trainable params: 128321 (501.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(128, return_sequences=True, input_shape=(12, 21)),\n",
    "    Dropout(0.2),\n",
    "    LSTM(64, return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "302eef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Scale target (zhvi_allhomes)\n",
    "y_scaler = MinMaxScaler()\n",
    "y_train_scaled = y_scaler.fit_transform(y_train_seq.reshape(-1, 1))\n",
    "y_test_scaled = y_scaler.transform(y_test_seq.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3308be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:From c:\\Users\\HP\\Desktop\\Reality_AI\\unet_env\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\HP\\Desktop\\Reality_AI\\unet_env\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "43/43 [==============================] - 5s 34ms/step - loss: 0.0162 - mae: 0.0926 - val_loss: 0.0054 - val_mae: 0.0618\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0060 - mae: 0.0588 - val_loss: 0.0092 - val_mae: 0.0676\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 21ms/step - loss: 0.0042 - mae: 0.0487 - val_loss: 0.0037 - val_mae: 0.0437\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 1s 19ms/step - loss: 0.0041 - mae: 0.0485 - val_loss: 0.0023 - val_mae: 0.0402\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 22ms/step - loss: 0.0033 - mae: 0.0423 - val_loss: 0.0035 - val_mae: 0.0446\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 1s 21ms/step - loss: 0.0031 - mae: 0.0387 - val_loss: 0.0041 - val_mae: 0.0504\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 18ms/step - loss: 0.0024 - mae: 0.0357 - val_loss: 0.0021 - val_mae: 0.0324\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0024 - mae: 0.0356 - val_loss: 0.0031 - val_mae: 0.0377\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0020 - mae: 0.0321 - val_loss: 0.0020 - val_mae: 0.0323\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0029 - val_mae: 0.0384\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0018 - mae: 0.0298 - val_loss: 0.0028 - val_mae: 0.0356\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0016 - mae: 0.0285 - val_loss: 0.0022 - val_mae: 0.0374\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 1s 20ms/step - loss: 0.0016 - mae: 0.0278 - val_loss: 0.0024 - val_mae: 0.0415\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 18ms/step - loss: 0.0019 - mae: 0.0307 - val_loss: 0.0027 - val_mae: 0.0359\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 22ms/step - loss: 0.0016 - mae: 0.0278 - val_loss: 0.0029 - val_mae: 0.0361\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.0017 - mae: 0.0283 - val_loss: 0.0026 - val_mae: 0.0356\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 1s 16ms/step - loss: 0.0012 - mae: 0.0242 - val_loss: 0.0013 - val_mae: 0.0238\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 1s 16ms/step - loss: 0.0012 - mae: 0.0239 - val_loss: 0.0021 - val_mae: 0.0331\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 1s 15ms/step - loss: 0.0012 - mae: 0.0236 - val_loss: 0.0015 - val_mae: 0.0250\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 1s 18ms/step - loss: 0.0013 - mae: 0.0245 - val_loss: 0.0020 - val_mae: 0.0316\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_scaled, y_train_scaled,\n",
    "    validation_data=(X_test_scaled, y_test_scaled),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b2b682c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 7ms/step\n",
      "RMSE: 7193.78\n",
      "MAE: 5144.57\n",
      "R¬≤ Score: 0.8933\n"
     ]
    }
   ],
   "source": [
    "y_pred_scaled = model.predict(X_test_scaled)\n",
    "y_pred = y_scaler.inverse_transform(y_pred_scaled)\n",
    "y_true = y_scaler.inverse_transform(y_test_scaled)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"R¬≤ Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9da43067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2326"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clear memory from previous training\n",
    "import gc\n",
    "del X_train_seq, y_train_seq, X_test_seq, y_test_seq, X_train_scaled, X_test_scaled, model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12922f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91580982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\HP\\Desktop\\Reality_AI\\unet_env\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import joblib\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# Optional: prettier plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f46b17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (2888110, 29)\n",
      "Test shape: (857820, 29)\n"
     ]
    }
   ],
   "source": [
    "# Load cleaned train/test data\n",
    "train = pd.read_csv(r'C:\\path\\to\\zillow\\cleaned\\city_time_series_train.csv', parse_dates=['date'])\n",
    "test = pd.read_csv(r'C:\\path\\to\\zillow\\cleaned\\city_time_series_test.csv', parse_dates=['date'])\n",
    "\n",
    "print(\"Train shape:\", train.shape)\n",
    "print(\"Test shape:\", test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c142194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'zhvi_allhomes'\n",
    "features = [\n",
    "    'zhvi_middletier', 'zhvi_singlefamilyresidence', 'zhvi_toptier',\n",
    "    'zhvipersqft_allhomes', 'zhvi_bottomtier', 'zhvi_4bedroom',\n",
    "    'zhvi_3bedroom', 'zhvi_5bedroomormore', 'zhvi_2bedroom', 'zhvi_condocoop',\n",
    "    'zri_allhomes', 'zri_allhomesplusmultifamily', 'zri_singlefamilyresidencerental',\n",
    "    'pricetorentratio_allhomes', 'zripersqft_allhomes', 'year',\n",
    "    'month', 'pctofhomesdecreasinginvalues_allhomes', 'pctofhomesincreasinginvalues_allhomes',\n",
    "    'inventoryraw_allhomes', 'inventoryseasonallyadjusted_allhomes'\n",
    "]\n",
    "\n",
    "TIMESTEPS = 12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19eb1149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_generator(df, features, target, feature_scaler, target_scaler, timesteps, batch_size=64):\n",
    "    regions = df['regionname'].unique()\n",
    "    X_batch, y_batch = [], []\n",
    "    \n",
    "    while True:  # Infinite generator for model.fit\n",
    "        for region in regions:\n",
    "            region_df = df[df['regionname'] == region].sort_values('date')\n",
    "            vals = region_df[features].values\n",
    "            targets = region_df[target].values\n",
    "            n = len(region_df)\n",
    "            \n",
    "            for i in range(n - timesteps):\n",
    "                X_window = vals[i:i+timesteps]\n",
    "                y_val = targets[i+timesteps]\n",
    "                \n",
    "                # Skip if any NaN\n",
    "                if np.isnan(X_window).any() or np.isnan(y_val):\n",
    "                    continue\n",
    "                \n",
    "                # Scale features\n",
    "                X_window_scaled = feature_scaler.transform(X_window)\n",
    "                \n",
    "                # Scale target\n",
    "                y_scaled = target_scaler.transform([[y_val]])[0]\n",
    "                \n",
    "                X_batch.append(X_window_scaled)\n",
    "                y_batch.append(y_scaled)\n",
    "                \n",
    "                if len(X_batch) == batch_size:\n",
    "                    yield np.array(X_batch, dtype=np.float32), np.array(y_batch, dtype=np.float32)\n",
    "                    X_batch, y_batch = [], []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9586ab10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\HP\\Desktop\\Reality_AI\\unet_env\\Lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py:148: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\HP\\Desktop\\Reality_AI\\unet_env\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 12, 128)           76800     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 12, 128)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 128321 (501.25 KB)\n",
      "Trainable params: 128321 (501.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_features = len(features)\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(128, return_sequences=True, input_shape=(TIMESTEPS, n_features)),\n",
    "    Dropout(0.2),\n",
    "    LSTM(64),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c75a8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Scalers created and fitted!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Feature scaler\n",
    "feature_scaler = StandardScaler()\n",
    "feature_scaler.fit(train[features].values)\n",
    "\n",
    "# Target scaler\n",
    "target_scaler = MinMaxScaler()\n",
    "target_scaler.fit(train[target].values.reshape(-1,1))\n",
    "\n",
    "print(\"‚úÖ Scalers created and fitted!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4aaac2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:From c:\\Users\\HP\\Desktop\\Reality_AI\\unet_env\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\HP\\Desktop\\Reality_AI\\unet_env\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1998/2000 [============================>.] - ETA: 0s - loss: 9.0554e-04 - mae: 0.0116\n",
      "Epoch 1: val_loss improved from inf to 0.00041, saving model to C:\\Users\\HP\\Desktop\\Reality_AI\\zillow\\zillow_lstm_best.keras\n",
      "2000/2000 [==============================] - 126s 61ms/step - loss: 9.0471e-04 - mae: 0.0116 - val_loss: 4.1002e-04 - val_mae: 0.0050\n",
      "Epoch 2/20\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 3.3264e-04 - mae: 0.0083\n",
      "Epoch 2: val_loss did not improve from 0.00041\n",
      "2000/2000 [==============================] - 127s 64ms/step - loss: 3.3249e-04 - mae: 0.0083 - val_loss: 0.0020 - val_mae: 0.0078\n",
      "Epoch 3/20\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 1.6339e-04 - mae: 0.0071\n",
      "Epoch 3: val_loss improved from 0.00041 to 0.00033, saving model to C:\\Users\\HP\\Desktop\\Reality_AI\\zillow\\zillow_lstm_best.keras\n",
      "2000/2000 [==============================] - 127s 64ms/step - loss: 1.6339e-04 - mae: 0.0071 - val_loss: 3.3391e-04 - val_mae: 0.0110\n",
      "Epoch 4/20\n",
      "1998/2000 [============================>.] - ETA: 0s - loss: 1.5808e-04 - mae: 0.0073\n",
      "Epoch 4: val_loss did not improve from 0.00033\n",
      "2000/2000 [==============================] - 126s 63ms/step - loss: 1.5796e-04 - mae: 0.0073 - val_loss: 9.0367e-04 - val_mae: 0.0048\n",
      "Epoch 5/20\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 1.9356e-04 - mae: 0.0074\n",
      "Epoch 5: val_loss improved from 0.00033 to 0.00023, saving model to C:\\Users\\HP\\Desktop\\Reality_AI\\zillow\\zillow_lstm_best.keras\n",
      "2000/2000 [==============================] - 499s 250ms/step - loss: 1.9356e-04 - mae: 0.0074 - val_loss: 2.3295e-04 - val_mae: 0.0056\n",
      "Epoch 6/20\n",
      "1998/2000 [============================>.] - ETA: 0s - loss: 6.8317e-05 - mae: 0.0051\n",
      "Epoch 6: val_loss did not improve from 0.00023\n",
      "2000/2000 [==============================] - 124s 62ms/step - loss: 6.8263e-05 - mae: 0.0051 - val_loss: 4.2889e-04 - val_mae: 0.0066\n",
      "Epoch 7/20\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 6.3082e-05 - mae: 0.0051\n",
      "Epoch 7: val_loss improved from 0.00023 to 0.00013, saving model to C:\\Users\\HP\\Desktop\\Reality_AI\\zillow\\zillow_lstm_best.keras\n",
      "2000/2000 [==============================] - 139s 69ms/step - loss: 6.3082e-05 - mae: 0.0051 - val_loss: 1.2923e-04 - val_mae: 0.0044\n",
      "Epoch 8/20\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 1.9018e-04 - mae: 0.0066\n",
      "Epoch 8: val_loss did not improve from 0.00013\n",
      "2000/2000 [==============================] - 169s 85ms/step - loss: 1.9034e-04 - mae: 0.0066 - val_loss: 0.0011 - val_mae: 0.0289\n",
      "Epoch 9/20\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 2.4803e-04 - mae: 0.0062\n",
      "Epoch 9: val_loss did not improve from 0.00013\n",
      "2000/2000 [==============================] - 168s 84ms/step - loss: 2.4803e-04 - mae: 0.0062 - val_loss: 0.0023 - val_mae: 0.0054\n",
      "Epoch 10/20\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 2.7401e-04 - mae: 0.0063\n",
      "Epoch 10: val_loss did not improve from 0.00013\n",
      "2000/2000 [==============================] - 167s 84ms/step - loss: 2.7401e-04 - mae: 0.0063 - val_loss: 1.3200e-04 - val_mae: 0.0069\n",
      "Epoch 11/20\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 1.3787e-04 - mae: 0.0058\n",
      "Epoch 11: val_loss improved from 0.00013 to 0.00011, saving model to C:\\Users\\HP\\Desktop\\Reality_AI\\zillow\\zillow_lstm_best.keras\n",
      "2000/2000 [==============================] - 162s 81ms/step - loss: 1.3787e-04 - mae: 0.0058 - val_loss: 1.0902e-04 - val_mae: 0.0065\n",
      "Epoch 12/20\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 8.8254e-05 - mae: 0.0052\n",
      "Epoch 12: val_loss improved from 0.00011 to 0.00006, saving model to C:\\Users\\HP\\Desktop\\Reality_AI\\zillow\\zillow_lstm_best.keras\n",
      "2000/2000 [==============================] - 165s 83ms/step - loss: 8.8254e-05 - mae: 0.0052 - val_loss: 5.8451e-05 - val_mae: 0.0074\n",
      "Epoch 13/20\n",
      "1998/2000 [============================>.] - ETA: 0s - loss: 6.9344e-05 - mae: 0.0047\n",
      "Epoch 13: val_loss did not improve from 0.00006\n",
      "2000/2000 [==============================] - 708s 354ms/step - loss: 6.9280e-05 - mae: 0.0047 - val_loss: 7.7885e-05 - val_mae: 0.0074\n",
      "Epoch 14/20\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 2.6806e-04 - mae: 0.0050\n",
      "Epoch 14: val_loss did not improve from 0.00006\n",
      "2000/2000 [==============================] - 112s 56ms/step - loss: 2.6806e-04 - mae: 0.0050 - val_loss: 1.1859e-04 - val_mae: 0.0089\n",
      "Epoch 15/20\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 1.4342e-04 - mae: 0.0051\n",
      "Epoch 15: val_loss did not improve from 0.00006\n",
      "2000/2000 [==============================] - 130s 65ms/step - loss: 1.4342e-04 - mae: 0.0051 - val_loss: 2.4783e-04 - val_mae: 0.0102\n",
      "Epoch 16/20\n",
      "1998/2000 [============================>.] - ETA: 0s - loss: 1.0174e-04 - mae: 0.0050\n",
      "Epoch 16: val_loss did not improve from 0.00006\n",
      "2000/2000 [==============================] - 154s 77ms/step - loss: 1.0167e-04 - mae: 0.0050 - val_loss: 2.4278e-04 - val_mae: 0.0150\n",
      "Epoch 17/20\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 8.0008e-05 - mae: 0.0051\n",
      "Epoch 17: val_loss did not improve from 0.00006\n",
      "2000/2000 [==============================] - 127s 63ms/step - loss: 8.0008e-05 - mae: 0.0051 - val_loss: 9.9289e-05 - val_mae: 0.0097\n",
      "Epoch 17: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Define callbacks\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=r\"C:\\Users\\HP\\Desktop\\Reality_AI\\zillow\\zillow_lstm_best.keras\",\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,  # stop if no improvement for 5 epochs\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Training parameters\n",
    "steps_per_epoch = 2000      # Adjust depending on your system\n",
    "validation_steps = 200\n",
    "epochs = 20\n",
    "batch_size = 64\n",
    "\n",
    "# Create generators\n",
    "train_gen = sequence_generator(train, features, target, feature_scaler, target_scaler, TIMESTEPS, batch_size)\n",
    "val_gen   = sequence_generator(test, features, target, feature_scaler, target_scaler, TIMESTEPS, batch_size)\n",
    "\n",
    "# Train model with callbacks\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps,\n",
    "    epochs=epochs,\n",
    "    callbacks=[checkpoint, early_stop],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f9ba691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Best model loaded\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model.save(\"zillow_lstm_best.keras\", save_format='tf')\n",
    "\n",
    "print(\"‚úÖ Best model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3fa9ad62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 72190.36\n",
      "MAE: 62374.30\n",
      "R¬≤ Score: 0.7962\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# üîπ Function to predict using generator in batches\n",
    "def batch_predict_generator(model, generator, steps):\n",
    "    y_pred_scaled = []\n",
    "    y_true_scaled = []\n",
    "    for i, (X_batch, y_batch) in enumerate(generator):\n",
    "        if i >= steps:  # stop after 'steps' batches\n",
    "            break\n",
    "        y_batch_pred = model.predict(X_batch, verbose=0)\n",
    "        y_pred_scaled.append(y_batch_pred)\n",
    "        y_true_scaled.append(y_batch)\n",
    "    return np.vstack(y_pred_scaled), np.vstack(y_true_scaled)\n",
    "\n",
    "# üîπ Predict from your generator\n",
    "y_pred_scaled, y_true_scaled = batch_predict_generator(model, val_gen, validation_steps)\n",
    "\n",
    "# üîπ Inverse-transform\n",
    "y_pred = target_scaler.inverse_transform(y_pred_scaled)\n",
    "y_true = target_scaler.inverse_transform(y_true_scaled)\n",
    "\n",
    "# üîπ Metrics\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"R¬≤ Score: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81fc6e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model for later use\n",
    "model.save(r\"C:\\Users\\HP\\Desktop\\Reality_AI\\zillow\\zillow_lstm_final.keras\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
